{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BAdRit5-S_gJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OXFKDubES_hj"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from numpy import std, pad, amax, abs\n",
    "from numpy.random import normal\n",
    "from numpy.fft import fftshift, ifftshift, fft2, ifft2 \n",
    "from cv2 import imshow as cv2_imshow\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5Ks3bQw6S_iA"
   },
   "outputs": [],
   "source": [
    "# Filenames\n",
    "filename = './pics/lenna.jpg'\n",
    "test_filenames = ['./pics/barraxx.bmp', './pics/BDBOB.jpg',\n",
    "                  './pics/pru2old.bmp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V00izQfS_lx"
   },
   "source": [
    "# Show original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "-bXscyVmS_l6",
    "outputId": "e8ed658a-9fdb-4326-a3fe-df5442a1bccb"
   },
   "outputs": [],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "cv.imshow(winname = 'original', mat = original)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnekptJeS_ma"
   },
   "source": [
    "# Blur + Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "apfi9kHyS_md"
   },
   "outputs": [],
   "source": [
    "def noisy_gauss(image, snr=20):\n",
    "      row, col, ch = image.shape\n",
    "      sigma_image = std(image)\n",
    "      sigma_noise = np.sqrt(sigma_image**2 * 10**(-snr/10))\n",
    "      noise = normal(loc=0.0, scale=sigma_noise, size=image.shape)\n",
    "      noisy = image + noise\n",
    "      noisy = np.where(noisy < 0,  0, noisy)\n",
    "      noisy = np.where(noisy > 255, 255, noisy)\n",
    "      noisy = noisy.astype(dtype=np.uint8)\n",
    "      return noisy, sigma_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiQzE9XlS_nw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "9UJUdwJgXnWF",
    "outputId": "5a4071fe-ab7c-4e40-d28c-121cfe02e441"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82pZBg_xbq36"
   },
   "source": [
    "# Wiener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VSVizJYwbk9o"
   },
   "outputs": [],
   "source": [
    "kernel_shape = (8, 8)\n",
    "kernel = 1 / kernel_shape[0] / kernel_shape[1]\n",
    "kernel *= np.ones(shape=kernel_shape)\n",
    "\n",
    "lenna_blur = cv.blur(src=original, ksize=(kernel_shape[0], kernel_shape[1]))\n",
    "lenna_blur_noise, noise_sigma = noisy_gauss(image=lenna_blur, snr=10)\n",
    "cv2_imshow('lena blured and noisy',lenna_blur_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[127, 139, 117, ..., 105,  88,  90],\n",
       "        [124, 111, 155, ...,  75, 100, 125],\n",
       "        [144, 139, 147, ...,  76, 106, 106],\n",
       "        ...,\n",
       "        [ 24,  13,  39, ...,  49,  32,  51],\n",
       "        [ 13,  14,  20, ...,  76,  65,  51],\n",
       "        [ 12,  30,   0, ...,  45,  43,  48]], dtype=uint8),\n",
       " array([[147, 123, 140, ..., 108,  97,  96],\n",
       "        [144, 120, 142, ..., 102,  94,  82],\n",
       "        [126, 144, 124, ..., 104,  75, 111],\n",
       "        ...,\n",
       "        [  7,  27,  36, ...,  28,  39,  42],\n",
       "        [ 31,  40,   0, ...,  40,  56,  47],\n",
       "        [  7,   5,  23, ...,  28,  19,  62]], dtype=uint8),\n",
       " array([[133, 124, 137, ..., 101, 106, 113],\n",
       "        [101, 146, 141, ...,  88,  79,  88],\n",
       "        [147, 134, 116, ..., 114,  59,  77],\n",
       "        ...,\n",
       "        [ 47,  13,  24, ...,  31,  37,  64],\n",
       "        [ 10,  41,  16, ...,  54,  71,  52],\n",
       "        [ 33,  14,  47, ...,  63,  72,  35]], dtype=uint8)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.split(lenna_blur_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yGTHZmGusV5n"
   },
   "outputs": [],
   "source": [
    "def recover(img, h, sn=None, wiener_inverse=False, show = True):\n",
    "    \n",
    "  #preparing H  \n",
    "  a, b, _ = img.shape\n",
    "  padded_kernel = np.zeros(shape=(a, b))\n",
    "  c, d = h.shape\n",
    "  padded_kernel[a//2 - c//2:a//2 + c//2 +1, b//2 - d//2: b//2 + d//2 +1] = h\n",
    "  centered_fft2_kernel = fftshift(fft2(padded_kernel))\n",
    "  #centered_fft2_kernel += 1.2\n",
    "  H = centered_fft2_kernel + 4\n",
    "\n",
    "  channels = []\n",
    "  for channel in cv.split(img):  #channel represents each R, B and G channel.\n",
    "    channel_fft = fftshift(fft2(channel))\n",
    "    if wiener_inverse:\n",
    "      sf = np.abs(channel_fft)**2\n",
    "      wiener_filter = np.divide(np.multiply(H.conjugate(), sf), np.multiply((np.abs(H))**2, sf) + sn ) \n",
    "      clean_lena = np.multiply(channel_fft, wiener_filter)\n",
    "      #clean_lena = np.multiply(np.divide(channel_fft, H), np.divide(np.abs(H)**2, (np.abs(H)**2 + np.divide(sn,sf))))\n",
    "    else:\n",
    "      clean_lena = np.divide(channel_fft, H)\n",
    "\n",
    "    # filtered image ifft2 and normalize to unity\n",
    "    clean_lena = np.abs(ifft2(ifftshift(clean_lena)))\n",
    "    maximum = amax(clean_lena)\n",
    "    clean_lena /= maximum\n",
    "    clean_lena *= 255\n",
    "    clean_lena = clean_lena.astype(np.uint8)\n",
    "    channels.append(clean_lena)\n",
    "\n",
    "  if len(channels) > 1:\n",
    "    clean_lena = cv.merge(channels)\n",
    "  else:\n",
    "    clean_lena = channels\n",
    "  newww = np.hstack((clean_lena, img))\n",
    "  if show:\n",
    "        cv2_imshow('recovered <LEFT>, original <RIGHT>', newww)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "  return clean_lena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 4, 12]\n",
      "[[0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]]\n"
     ]
    }
   ],
   "source": [
    "def center_image(large_image, center_image, debug = False):\n",
    "    x_min = (large_image.shape[0] // 2) - (center_image.shape[0] // 2)\n",
    "    x_max = (large_image.shape[0] // 2) + (center_image.shape[0] // 2)\n",
    "    y_min = (large_image.shape[1] // 2) - (center_image.shape[1] // 2)\n",
    "    y_max = (large_image.shape[1] // 2) + (center_image.shape[1] // 2)\n",
    "    result = np.zeros((large_image.shape[0], large_image.shape[1]))\n",
    "    result[x_min:x_max, y_min:y_max] = center_image\n",
    "    if debug:\n",
    "        test_list = [x_min, x_max, y_min, y_max]\n",
    "        print(test_list)\n",
    "    return result\n",
    "\n",
    "kernel_padded = center_image(np.zeros((16, 16)), kernel, debug = True)\n",
    "print(kernel_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_v2(degradated_img, psf, sn=None, wiener_inverse=False, show = False):\n",
    "    #paso al espacio de frecuencias la psf y la imagen degradada. El tamaño de la psf puede ser \n",
    "    #menor al tamaño de la imagen degradada.\n",
    "    \n",
    "    #F = G.H, F: imagen original, G: imagen degragaga, H:sistema\n",
    "    channels = []\n",
    "    for img_channel in cv.split(degradated_img):\n",
    "        #print(img_channel.shape)\n",
    "        psf_padded = center_image(img_channel, psf) ## en esta funcion se utilizará el tamaño de la imagen para \n",
    "                                                    ##crear un nuevo kernel con dicho tamaño.\n",
    "        H = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(psf_padded)))\n",
    "        G = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(img_channel)))\n",
    "        H = H +1\n",
    "        if (wiener_inverse) and (not(sn.any() == None)):           #WIENER OPTION\n",
    "            psd_img_channel = np.fft.fft2(np.corrcoef(img_channel))\n",
    "            noise_relation = np.abs(sn / psd_img_channel)\n",
    "            #print(noise_relation)\n",
    "            \n",
    "            W = H.conj()/((H*H.conj()) + noise_relation)\n",
    "            #W = np.where(W == 0, W, 1)\n",
    "            F = np.multiply(G, W)\n",
    "            f = np.abs(np.fft.ifftshift((np.fft.ifft2(np.fft.ifftshift(F)))))\n",
    "        else:                        #INVERSE_SIMPLE OPTION\n",
    "            #H = np.where(H == 0, H, 1)\n",
    "            F = np.divide(G, H +1)\n",
    "            f = np.abs(np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(F))))\n",
    "                       \n",
    "        channels.append(f)\n",
    "        \n",
    "    if len(channels) > 1:\n",
    "        clean_img = cv.merge(channels)\n",
    "        \n",
    "    maximum = np.max(clean_img)\n",
    "    clean_img = np.uint8((clean_img/maximum)*255)\n",
    "    \n",
    "    return clean_img\n",
    "\n",
    "def mse_metric(x, y):\n",
    "    a = x.shape[0]\n",
    "    b = x.shape[1]\n",
    "    c = x.shape[2]\n",
    "    x = x.reshape(1, a*b*c)\n",
    "    y = y.reshape(1, a*b*c)\n",
    "    return  np.mean((x - y)**2)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 86.77205912272136\n",
      "MSE inverse_simple 98.16919453938802\n",
      "MSE Wiener 107.78720601399739\n"
     ]
    }
   ],
   "source": [
    "noise_shape = (lenna_blur_noise.shape[0], lenna_blur_noise.shape[1])\n",
    "noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "wiener_result = recover_v2(lenna_blur_noise, kernel, sn=noise, wiener_inverse=True)\n",
    "inverse_simple = recover_v2(lenna_blur_noise, kernel, wiener_inverse=False)\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, lenna_blur_noise)}')\n",
    "print(f'MSE inverse_simple {mse_metric(original, inverse_simple)}')\n",
    "print(f'MSE Wiener {mse_metric(original, wiener_result)}')\n",
    "\n",
    "wiener_vs_inverse_stacked = np.hstack((lenna_blur_noise, inverse_simple, wiener_result))\n",
    "cv2_imshow('degradated <LEFT>, inverse_simple <CENTER> and Wiener <RIGHT>', wiener_vs_inverse_stacked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "VuJjD7nBHRRy",
    "outputId": "95cc9461-ff99-4419-ec9e-56847c478e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 66 118  48]\n",
      "  [141  74 132]\n",
      "  [ 59 118  39]\n",
      "  ...\n",
      "  [131  79 107]\n",
      "  [ 67 111  54]\n",
      "  [134  75 119]]\n",
      "\n",
      " [[131  80 116]\n",
      "  [ 57 100  40]\n",
      "  [141  81 126]\n",
      "  ...\n",
      "  [ 70  95  55]\n",
      "  [129  83 112]\n",
      "  [ 66  95  46]]\n",
      "\n",
      " [[ 71 102  53]\n",
      "  [138  91 129]\n",
      "  [ 62 103  42]\n",
      "  ...\n",
      "  [122  94 112]\n",
      "  [ 76  95  52]\n",
      "  [133  93 116]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[119  48 119]\n",
      "  [ 58 118  20]\n",
      "  [126  50 130]\n",
      "  ...\n",
      "  [ 69 111  53]\n",
      "  [117  50 110]\n",
      "  [ 63 114  38]]\n",
      "\n",
      " [[ 63 121  24]\n",
      "  [130  60 143]\n",
      "  [ 57 117  14]\n",
      "  ...\n",
      "  [126  61 114]\n",
      "  [ 66 118  37]\n",
      "  [130  59 130]]\n",
      "\n",
      " [[117  52 116]\n",
      "  [ 60 111  27]\n",
      "  [123  59 125]\n",
      "  ...\n",
      "  [ 72 106  57]\n",
      "  [117  57 109]\n",
      "  [ 66 111  40]]]\n"
     ]
    }
   ],
   "source": [
    "noise_shape = (lenna_blur_noise.shape[0], lenna_blur_noise.shape[1])\n",
    "noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "wiener_result = recover_v2(lenna_blur_noise, kernel, sn=noise, wiener_inverse=True)\n",
    "print(wiener_result)\n",
    "cv2_imshow('wiener vs inverse_simple', wiener_result)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BPiaiLMLKxq"
   },
   "source": [
    "# Inverse Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "Qk6SbUFVLHzn",
    "outputId": "9b23649d-67e1-4562-c701-fa4c158a410b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (8,8) into shape (9,9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-361a9ae04931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minverse_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlenna_blur_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwiener_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-e274afda262e>\u001b[0m in \u001b[0;36mrecover\u001b[1;34m(img, h, sn, wiener_inverse, show)\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mpadded_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mpadded_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m   \u001b[0mcentered_fft2_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfftshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfft2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;31m#centered_fft2_kernel += 1.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (8,8) into shape (9,9)"
     ]
    }
   ],
   "source": [
    "inverse_result = recover(img=lenna_blur_noise, h=kernel, wiener_inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "70Veee5aNPU9",
    "outputId": "00e24e81-c87c-4181-e197-077af2105c77"
   },
   "outputs": [],
   "source": [
    "stacked = np.hstack((wiener_result, inverse_result))\n",
    "cv2_imshow('wiener vs inverse_simple', stacked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "print('Wiener vs Inverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFsvKj7TT-IT"
   },
   "outputs": [],
   "source": [
    "def estimate_blur_kernel(img):\n",
    "  #estimated = None\n",
    "  estimated = (1/9)*np.ones((3, 3))\n",
    "  return estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "SGuaPO9tQgxt",
    "outputId": "ba8dfb35-63b0-4a96-c798-152d11d0c4f6"
   },
   "outputs": [],
   "source": [
    "for name in test_filenames:\n",
    "  img = cv.imread(name)\n",
    "  if img.any() == None:\n",
    "        print(\"invalid image\")\n",
    "  noise_shape = (img.shape[0], img.shape[1])\n",
    "  # assuming noise_sigma based on lena... should change the estimated value\n",
    "  # based on the new image \n",
    "  noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "  kernel = estimate_blur_kernel(img)\n",
    "  wiener_result = recover(img=img, h=kernel, sn=noise, wiener_inverse=True, show = False)\n",
    "  inverse_result = recover(img=img, h=kernel, wiener_inverse=False, show = False)\n",
    "  stacked = np.hstack((wiener_result, inverse_result))\n",
    "  cv2_imshow('wiener vs inverse', stacked)\n",
    "  cv.waitKey(0)\n",
    "  cv.destroyAllWindows()\n",
    "  print('Wiener vs Inverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blind Deconvolution\n",
    "\n",
    "Blind Deconvolution (Deconvolución a ciegas) consiste en un algoritmo que reconstruye la imagen sin necesidad de tener el modelo exacto de la función \"PSF\" (es por esto que se le da el nombre de \"a ciegas\"). El algortimo parte de una función PSF \"a priori\", o supone una forma de función PSF, pero luego la ajusta según la imagen de entrada. Para ajustar la función PSF, el algoritmo suele usar las secciones más brillantes de la imagen, que se vieron menos afectadas por el nivel de ruido.\n",
    "Para la implementación, se utilizó la función \"deconvblind\" de Matlab, a la que se la paso la sencilla función PSF a priori como una matriz de 12x12 de unos. Con esto logro obtenerse resultados aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_code_img = cv.imread('deconvCodeMATLAB.png')\n",
    "#print(matlab_code_img)\n",
    "cv.imshow('matlab code deconvblind', matlab_code_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image_blind = cv.imread('image_in_deconvblind.bmp') \n",
    "out_image_blind = cv.imread('image_out_deconvblind.bmp') \n",
    "in_out_images = np.hstack((in_image_blind, out_image_blind))\n",
    "cv.imshow('in image -LEFT- vs out -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Blur\n",
    "\n",
    "Para simular el motion blur que degrada una imagen debido a un movimiento de una cámara al momento de tomar la foto, se realizan kernels con unos en una columna (en caso de motion vertical) o en una fila (en caso de blur horizonral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_h_motion = np.zeros((21, 21))\n",
    "kernel_v_motion = np.zeros((21, 21))\n",
    "\n",
    "k = 1 / 21\n",
    "\n",
    "kernel_h_motion[2, :] = k\n",
    "\n",
    "kernel_v_motion[:, 2] = k\n",
    "\n",
    "\n",
    "\n",
    "#print(kernel_v_motion)\n",
    "#print(kernel_h_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertical Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "vertical_moved = cv.filter2D(original, -1, kernel_v_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#vertical_recovered = recover(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "vertical_recovered = recover(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=False, show = False)\n",
    "in_out_images = np.hstack((original, vertical_moved, vertical_recovered))\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizontal Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "horizontal_moved = cv.filter2D(original, -1, kernel_h_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#horizontal_recovered = recover(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "horizontal_recovered = recover(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=False, show = False)\n",
    "in_out_images = np.hstack((original, horizontal_moved, horizontal_recovered))\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_reconstruction - Copy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (images)",
   "language": "python",
   "name": "images"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
