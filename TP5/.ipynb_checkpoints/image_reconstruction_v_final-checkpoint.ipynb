{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BAdRit5-S_gJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OXFKDubES_hj"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from numpy import std, pad, amax, abs\n",
    "from numpy.random import normal\n",
    "from numpy.fft import fftshift, ifftshift, fft2, ifft2 \n",
    "from cv2 import imshow as cv2_imshow\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5Ks3bQw6S_iA"
   },
   "outputs": [],
   "source": [
    "# Filenames\n",
    "filename = './pics/lenna.jpg'\n",
    "test_filenames = ['./pics/barraxx.bmp', './pics/BDBOB.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V00izQfS_lx"
   },
   "source": [
    "# Show original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "-bXscyVmS_l6",
    "outputId": "e8ed658a-9fdb-4326-a3fe-df5442a1bccb"
   },
   "outputs": [],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "cv.imshow(winname = 'original', mat = original)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnekptJeS_ma"
   },
   "source": [
    "# Blur + Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "apfi9kHyS_md"
   },
   "outputs": [],
   "source": [
    "def noisy_gauss(image, snr=20):\n",
    "      row, col, ch = image.shape\n",
    "      sigma_image = std(image)\n",
    "      sigma_noise = np.sqrt(sigma_image**2 * 10**(-snr/10))\n",
    "      noise = normal(loc=0.0, scale=sigma_noise, size=image.shape)\n",
    "      noisy = image + noise\n",
    "      noisy = np.where(noisy < 0,  0, noisy)\n",
    "      noisy = np.where(noisy > 255, 255, noisy)\n",
    "      noisy = noisy.astype(dtype=np.uint8)\n",
    "      return noisy, sigma_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82pZBg_xbq36"
   },
   "source": [
    "# Wiener and Inverse Recovering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VSVizJYwbk9o"
   },
   "outputs": [],
   "source": [
    "kernel_shape = (8, 8)\n",
    "kernel = 1 / kernel_shape[0] / kernel_shape[1]\n",
    "kernel *= np.ones(shape=kernel_shape)\n",
    "\n",
    "lenna_blur = cv.blur(src=original, ksize=(kernel_shape[0], kernel_shape[1]))\n",
    "lenna_blur_noise, noise_sigma = noisy_gauss(image=lenna_blur, snr=10)\n",
    "cv2_imshow('lena blured and noisy',lenna_blur_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[148, 157, 148, ...,  86,  99,  94],\n",
       "        [128, 146, 123, ...,  89,  75, 113],\n",
       "        [115, 126, 124, ...,  80, 103,  94],\n",
       "        ...,\n",
       "        [ 29,  22,  21, ...,  63,  22,  41],\n",
       "        [  0,  30,  20, ...,  43,  42,  51],\n",
       "        [ 11,   2,  58, ...,  57,  57,  43]], dtype=uint8),\n",
       " array([[107, 106, 150, ...,  62,  73, 103],\n",
       "        [134, 135, 106, ..., 121, 101,  98],\n",
       "        [146, 131, 120, ...,  78,  78,  89],\n",
       "        ...,\n",
       "        [ 60,  17,  36, ...,  67,  44,  28],\n",
       "        [  0,  31,  42, ...,  41,  58,  48],\n",
       "        [ 31,  48,  22, ...,  56,  54,  24]], dtype=uint8),\n",
       " array([[132, 124, 144, ..., 114, 104,  85],\n",
       "        [127, 138, 145, ...,  96,  96, 100],\n",
       "        [150, 128, 120, ...,  97,  90,  98],\n",
       "        ...,\n",
       "        [ 18,  59,  49, ...,  32,  53,  18],\n",
       "        [ 57,  17,  27, ...,  51,  58,  35],\n",
       "        [ 28,  31,  31, ...,  45,  70,  48]], dtype=uint8)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.split(lenna_blur_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 4, 12]\n",
      "[[0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]]\n"
     ]
    }
   ],
   "source": [
    "def center_image(large_image, center_image, debug = False):\n",
    "    x_min = (large_image.shape[0] // 2) - (center_image.shape[0] // 2)\n",
    "    x_max = (large_image.shape[0] // 2) + (center_image.shape[0] // 2)\n",
    "    y_min = (large_image.shape[1] // 2) - (center_image.shape[1] // 2)\n",
    "    y_max = (large_image.shape[1] // 2) + (center_image.shape[1] // 2)\n",
    "    result = np.zeros((large_image.shape[0], large_image.shape[1]))\n",
    "    result[x_min:x_max, y_min:y_max] = center_image\n",
    "    if debug:\n",
    "        test_list = [x_min, x_max, y_min, y_max]\n",
    "        print(test_list)\n",
    "    return result\n",
    "\n",
    "kernel_padded = center_image(np.zeros((16, 16)), kernel, debug = True)\n",
    "print(kernel_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img):\n",
    "    minimum = np.min(img)\n",
    "    img_normalized = img - np.sign(minimum)*np.abs(minimum)\n",
    "    img_normalized = img_normalized/np.max(img_normalized)\n",
    "    return img_normalized\n",
    "def recover_v2(degradated_img, psf, sn=None, wiener_inverse=False, show = False):\n",
    "    #paso al espacio de frecuencias la psf y la imagen degradada. El tamaño de la psf puede ser \n",
    "    #menor al tamaño de la imagen degradada.\n",
    "    \n",
    "    #F = G.H, F: imagen original, G: imagen degragaga, H:sistema\n",
    "    channels = []\n",
    "    degradated_img = normalize_img(degradated_img)\n",
    "    for img_channel in cv.split(degradated_img):\n",
    "        #print(img_channel.shape)\n",
    "        psf_padded = center_image(img_channel, psf) ## en esta funcion se utilizará el tamaño de la imagen para \n",
    "                                                    ##crear un nuevo kernel con dicho tamaño.\n",
    "        H = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(psf_padded)))\n",
    "        G = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(img_channel)))\n",
    "        if (wiener_inverse) and (not(sn.any() == None)):           #WIENER OPTION\n",
    "            \n",
    "            psd_img_channel = np.ones((img_channel.shape[0], img_channel.shape[1]))\n",
    "            aux = np.fft.fft2(np.corrcoef(img_channel))\n",
    "            psd_img_channel[0:aux.shape[0], 0:aux.shape[1]] = aux\n",
    "            \n",
    "            sn_matrix = np.zeros((img_channel.shape[0], img_channel.shape[1]))\n",
    "            \n",
    "            np.fill_diagonal(sn_matrix, sn[0])\n",
    "            \n",
    "            Sn_matrix = np.fft.fft2(sn)\n",
    "            \n",
    "            noise_relation = np.abs( Sn_matrix/ psd_img_channel) + 256*256\n",
    "            #print(noise_relation)\n",
    "            H = H + 10\n",
    "            W = H.conj()/((H*H.conj()) + noise_relation)\n",
    "            #W = np.where(W == 0, W, 1)\n",
    "            F = np.multiply(G, W)\n",
    "            f = np.abs(np.fft.ifftshift((np.fft.ifft2(np.fft.ifftshift(F)))))\n",
    "            #print(f.max())\n",
    "            #print(f.min())\n",
    "            maximum = np.max(f)\n",
    "            f = np.uint8((f/maximum)*256)\n",
    "        else:                        #INVERSE_SIMPLE OPTION\n",
    "            #H = np.where(H == 0, H, 1)\n",
    "            F = np.divide(G, H + 10)\n",
    "            f = np.abs(np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(F))))\n",
    "            maximum = np.max(f)\n",
    "            f = np.uint8((f/maximum)*256)\n",
    "        #print(f.max())\n",
    "        #print(f.min())\n",
    "        \n",
    "        #cv2_imshow('channel', f)\n",
    "        #cv.waitKey(0)\n",
    "        #cv.destroyAllWindows()\n",
    "        channels.append(f)\n",
    "        \n",
    "    if len(channels) > 1:\n",
    "        clean_img = cv.merge(channels)\n",
    "        \n",
    "    \n",
    "    return clean_img\n",
    "\n",
    "def mse_metric(x, y, dim = 3):\n",
    "    a = x.shape[0]\n",
    "    b = x.shape[1]\n",
    "    if dim > 2:\n",
    "        c = x.shape[2]\n",
    "    else:\n",
    "        c = 1     \n",
    "    x = x.reshape(1, a*b*c)\n",
    "    y = y.reshape(1, a*b*c)\n",
    "    return  np.mean((x - y)**2)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:23: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 86.49140930175781\n",
      "MSE inverse_simple 88.74109395345052\n",
      "MSE Wiener 84.93702189127605\n"
     ]
    }
   ],
   "source": [
    "noise_shape = (lenna_blur_noise.shape[0], lenna_blur_noise.shape[1])\n",
    "noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "wiener_result = recover_v2(lenna_blur_noise, kernel, sn=noise, wiener_inverse=True)\n",
    "inverse_simple = recover_v2(lenna_blur_noise, kernel, wiener_inverse=False)\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, lenna_blur_noise)}')\n",
    "print(f'MSE inverse_simple {mse_metric(original, inverse_simple)}')\n",
    "print(f'MSE Wiener {mse_metric(original, wiener_result)}')\n",
    "\n",
    "wiener_vs_inverse_stacked = np.hstack((lenna_blur_noise, inverse_simple, wiener_result))\n",
    "cv2_imshow('degradated <LEFT>, inverse_simple <CENTER> and Wiener <RIGHT>', wiener_vs_inverse_stacked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qFsvKj7TT-IT"
   },
   "outputs": [],
   "source": [
    "def estimate_blur_kernel(img):\n",
    "  #estimated = None\n",
    "  estimated = (1/9)*np.ones((4, 4))\n",
    "  return estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "SGuaPO9tQgxt",
    "outputId": "ba8dfb35-63b0-4a96-c798-152d11d0c4f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:23: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiener vs Inverse\n",
      "Wiener vs Inverse\n"
     ]
    }
   ],
   "source": [
    "for name in test_filenames:\n",
    "  img = cv.imread(name)\n",
    "  if img.any() == None:\n",
    "        print(\"invalid image\")\n",
    "  noise_shape = (img.shape[0], img.shape[1])\n",
    "  # assuming noise_sigma based on lena... should change the estimated value\n",
    "  # based on the new image \n",
    "  noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "  kernel = estimate_blur_kernel(img)\n",
    "  wiener_result = recover_v2(img, kernel, sn=noise, wiener_inverse=True, show = False)\n",
    "  inverse_result = recover_v2(img, kernel, wiener_inverse=False, show = False)\n",
    "  stacked = np.hstack((wiener_result, inverse_result))\n",
    "  cv2_imshow('wiener vs inverse', stacked)\n",
    "  cv.waitKey(0)\n",
    "  cv.destroyAllWindows()\n",
    "  print('Wiener vs Inverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blind Deconvolution\n",
    "\n",
    "Blind Deconvolution (Deconvolución a ciegas) consiste en un algoritmo que reconstruye la imagen sin necesidad de tener el modelo exacto de la función \"PSF\" (es por esto que se le da el nombre de \"a ciegas\"). El algortimo parte de una función PSF \"a priori\", o supone una forma de función PSF, pero luego la ajusta según la imagen de entrada. Para ajustar la función PSF, el algoritmo suele usar las secciones más brillantes de la imagen, que se vieron menos afectadas por el nivel de ruido.\n",
    "Para la implementación, se utilizó la función \"deconvblind\" de Matlab, a la que se la paso la sencilla función PSF a priori como una matriz de 12x12 de unos. Con esto logro obtenerse resultados aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_code_img = cv.imread('deconvCodeMATLAB.png')\n",
    "#print(matlab_code_img)\n",
    "cv.imshow('matlab code deconvblind', matlab_code_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image_blind = cv.imread('image_in_deconvblind.bmp') \n",
    "out_image_blind = cv.imread('image_out_deconvblind.bmp') \n",
    "in_out_images = np.hstack((in_image_blind, out_image_blind))\n",
    "cv.imshow('in image -LEFT- vs out -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Blur\n",
    "\n",
    "Para simular el motion blur que degrada una imagen debido a un movimiento de una cámara al momento de tomar la foto, se realizan kernels con unos en una columna (en caso de motion vertical) o en una fila (en caso de blur horizonral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_h_motion = np.zeros((20, 20))\n",
    "kernel_v_motion = np.zeros((20, 20))\n",
    "\n",
    "k = 1 / 20\n",
    "\n",
    "kernel_h_motion[2, :] = k\n",
    "\n",
    "kernel_v_motion[:, 2] = k\n",
    "\n",
    "\n",
    "\n",
    "#print(kernel_v_motion)\n",
    "#print(kernel_h_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertical Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 86.298583984375\n",
      "MSE recovered 90.34086608886719\n"
     ]
    }
   ],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "vertical_moved = cv.filter2D(original, -1, kernel_v_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#vertical_recovered = recover(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "vertical_recovered = recover_v2(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=False, show = False)\n",
    "in_out_images = np.hstack((original, vertical_moved, vertical_recovered))\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, vertical_moved)}')\n",
    "print(f'MSE recovered {mse_metric(original, vertical_recovered)}')\n",
    "\n",
    "\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizontal Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:23: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 82.41682434082031\n",
      "MSE recovered 96.74465942382812\n"
     ]
    }
   ],
   "source": [
    "\n",
    "horizontal_moved = cv.filter2D(original, -1, kernel_h_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#horizontal_recovered = recover(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "horizontal_recovered = recover_v2(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "in_out_images = np.hstack((original, horizontal_moved, horizontal_recovered))\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, horizontal_moved)}')\n",
    "print(f'MSE recovered {mse_metric(original, horizontal_recovered)}')\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Determinísitca (Tikhonov - Miller)\n",
    "\n",
    "A continuación se plantea una función para implementar la restauración teniendo en cuenta la regularización para poder condicionar mejor el problema.\n",
    "\n",
    "La función a minimizar por este método es la siguiente:\n",
    "$$ E{||g-H \\hat{f}||^{2} + \\alpha ||C\\hat{f}||^{2}} $$\n",
    "\n",
    "Entonces se llega a la siguiente solución:\n",
    "\n",
    "$$ \\hat{f} = (H^{T}H + \\alpha C^{T}C)H^{T}g $$\n",
    "\n",
    "\n",
    "Donde H es la respuesta del sistema, C representa la matriz de condición dada por el laplaciano, g es la imagen degradada y alpha es un factor de regularización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tikhonov_miller(g, h, c, alpha = 15):\n",
    "    \n",
    "    channels = []\n",
    "    for g_channel in cv.split(g):\n",
    "        g_channel = normalize_img(g_channel)\n",
    "        h_padded = center_image(g_channel, h)\n",
    "        c_padded = center_image(g_channel, c)\n",
    "    \n",
    "        C = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(c_padded)))\n",
    "        H = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(h_padded)))\n",
    "        G = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(g_channel)))\n",
    "        F_hat = (H.conj()*G) * (H.conj()*H + alpha*C.conj()*C)\n",
    "        f_hat = np.abs(np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(F_hat))))\n",
    "        maximum = np.max(f_hat)\n",
    "        f_hat = np.uint8((f_hat/maximum)*256)\n",
    "        channels.append(f_hat)\n",
    "        \n",
    "        \n",
    "    if len(channels) > 1:\n",
    "        clean_img = cv.merge(channels)  \n",
    "    \n",
    "   \n",
    "    \n",
    "    return clean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 86.49140930175781\n",
      "MSE recovered 80.93547058105469\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[-0.25, -0.25, -0.25, -0.25], [-0.25, 1, 1, -0.25], [-0.25, 1, 1, -0.25], [-0.25, -0.25, -0.25, -0.25]])\n",
    "h = np.ones((16, 16))/(16*16)\n",
    "g = lenna_blur_noise\n",
    "f_hat = tikhonov_miller(g, h, c)\n",
    "\n",
    "original_ = original\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original_, g)}')\n",
    "print(f'MSE recovered {mse_metric(original_, f_hat)}')\n",
    "\n",
    "tikhonov_stacked = np.hstack((g, f_hat))\n",
    "cv2_imshow('degradated <LEFT> vs recovered <RIGHT>', tikhonov_stacked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método Iterativo\n",
    "Se utiliza el método \"Constrained Least Squares\" que utiliza lo siguiente:\n",
    "\n",
    "$$ f_{k-1} = f_{k}H^{T}g -  (H^{T}H + \\alpha C^{T}C)f_{}k $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iterative_recovering(g, h, c):\n",
    "    \n",
    "\n",
    "    h = center_image(np.array(g), np.array(h))\n",
    "    c = center_image(np.array(g), np.array(c))\n",
    "    #\n",
    "    alpha = 15\n",
    "\n",
    "    mod_h = np.transpose(h)*h\n",
    "    mod_c = np.transpose(c)*c\n",
    "    eig,eigv=np.linalg.eig(mod_h + alpha*mod_c)\n",
    "    g = normalize_img(g)\n",
    "    beta=1/max(eig)\n",
    "\n",
    "    c = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(c)))\n",
    "    h = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(h)))\n",
    "    g = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(g)))\n",
    "    fo=beta*h.conj()*g\n",
    "    fk=np.copy(fo)\n",
    "\n",
    "\n",
    "    for i in range(2):\n",
    "        #Ecuación de actualización\n",
    "        fk = fo + fk - beta*(mod_h+alpha*mod_c)*(fk)\n",
    "        f_final = np.copy(fk)\n",
    "    f_final = np.abs(np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(f_final))))\n",
    "    maximum = np.max(f_final)\n",
    "    f_final = np.uint8((f_final/maximum)*256)\n",
    "    return f_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = cv.imread('./pics/lenna.jpg', 0)\n",
    "g = cv.filter2D(orig, -1, h)\n",
    "recovered_iterative = iterative_recovering(g, h, c)\n",
    "\n",
    "#print(f'MSE degradated {mse_metric(orig, g, dim = 2)}')\n",
    "#print(f'MSE recovered {mse_metric(orig, recovered_iterative, dim = 2)}')\n",
    "\n",
    "in_out_images = np.hstack((orig, g, recovered_iterative))    \n",
    "\n",
    "cv.imshow('original - LEFT- blured image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_reconstruction - Copy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (images)",
   "language": "python",
   "name": "images"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
