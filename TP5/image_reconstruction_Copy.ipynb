{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BAdRit5-S_gJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OXFKDubES_hj"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from numpy import std, pad, amax, abs\n",
    "from numpy.random import normal\n",
    "from numpy.fft import fftshift, ifftshift, fft2, ifft2 \n",
    "from cv2 import imshow as cv2_imshow\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "5Ks3bQw6S_iA"
   },
   "outputs": [],
   "source": [
    "# Filenames\n",
    "filename = './pics/lenna.jpg'\n",
    "test_filenames = ['./pics/barraxx.bmp', './pics/BDBOB.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V00izQfS_lx"
   },
   "source": [
    "# Show original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "-bXscyVmS_l6",
    "outputId": "e8ed658a-9fdb-4326-a3fe-df5442a1bccb"
   },
   "outputs": [],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "cv.imshow(winname = 'original', mat = original)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnekptJeS_ma"
   },
   "source": [
    "# Blur + Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "apfi9kHyS_md"
   },
   "outputs": [],
   "source": [
    "def noisy_gauss(image, snr=20):\n",
    "      row, col, ch = image.shape\n",
    "      sigma_image = std(image)\n",
    "      sigma_noise = np.sqrt(sigma_image**2 * 10**(-snr/10))\n",
    "      noise = normal(loc=0.0, scale=sigma_noise, size=image.shape)\n",
    "      noisy = image + noise\n",
    "      noisy = np.where(noisy < 0,  0, noisy)\n",
    "      noisy = np.where(noisy > 255, 255, noisy)\n",
    "      noisy = noisy.astype(dtype=np.uint8)\n",
    "      return noisy, sigma_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82pZBg_xbq36"
   },
   "source": [
    "# Wiener and Inverse Recovering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VSVizJYwbk9o"
   },
   "outputs": [],
   "source": [
    "kernel_shape = (8, 8)\n",
    "kernel = 1 / kernel_shape[0] / kernel_shape[1]\n",
    "kernel *= np.ones(shape=kernel_shape)\n",
    "\n",
    "lenna_blur = cv.blur(src=original, ksize=(kernel_shape[0], kernel_shape[1]))\n",
    "lenna_blur_noise, noise_sigma = noisy_gauss(image=lenna_blur, snr=10)\n",
    "cv2_imshow('lena blured and noisy',lenna_blur_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[127, 139, 117, ..., 105,  88,  90],\n",
       "        [124, 111, 155, ...,  75, 100, 125],\n",
       "        [144, 139, 147, ...,  76, 106, 106],\n",
       "        ...,\n",
       "        [ 24,  13,  39, ...,  49,  32,  51],\n",
       "        [ 13,  14,  20, ...,  76,  65,  51],\n",
       "        [ 12,  30,   0, ...,  45,  43,  48]], dtype=uint8),\n",
       " array([[147, 123, 140, ..., 108,  97,  96],\n",
       "        [144, 120, 142, ..., 102,  94,  82],\n",
       "        [126, 144, 124, ..., 104,  75, 111],\n",
       "        ...,\n",
       "        [  7,  27,  36, ...,  28,  39,  42],\n",
       "        [ 31,  40,   0, ...,  40,  56,  47],\n",
       "        [  7,   5,  23, ...,  28,  19,  62]], dtype=uint8),\n",
       " array([[133, 124, 137, ..., 101, 106, 113],\n",
       "        [101, 146, 141, ...,  88,  79,  88],\n",
       "        [147, 134, 116, ..., 114,  59,  77],\n",
       "        ...,\n",
       "        [ 47,  13,  24, ...,  31,  37,  64],\n",
       "        [ 10,  41,  16, ...,  54,  71,  52],\n",
       "        [ 33,  14,  47, ...,  63,  72,  35]], dtype=uint8)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.split(lenna_blur_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 4, 12]\n",
      "[[0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.015625 0.015625 0.015625 0.015625\n",
      "  0.015625 0.015625 0.015625 0.015625 0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.       0.       0.\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.      ]]\n"
     ]
    }
   ],
   "source": [
    "def center_image(large_image, center_image, debug = False):\n",
    "    x_min = (large_image.shape[0] // 2) - (center_image.shape[0] // 2)\n",
    "    x_max = (large_image.shape[0] // 2) + (center_image.shape[0] // 2)\n",
    "    y_min = (large_image.shape[1] // 2) - (center_image.shape[1] // 2)\n",
    "    y_max = (large_image.shape[1] // 2) + (center_image.shape[1] // 2)\n",
    "    result = np.zeros((large_image.shape[0], large_image.shape[1]))\n",
    "    result[x_min:x_max, y_min:y_max] = center_image\n",
    "    if debug:\n",
    "        test_list = [x_min, x_max, y_min, y_max]\n",
    "        print(test_list)\n",
    "    return result\n",
    "\n",
    "kernel_padded = center_image(np.zeros((16, 16)), kernel, debug = True)\n",
    "print(kernel_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_v2(degradated_img, psf, sn=None, wiener_inverse=False, show = False):\n",
    "    #paso al espacio de frecuencias la psf y la imagen degradada. El tamaño de la psf puede ser \n",
    "    #menor al tamaño de la imagen degradada.\n",
    "    \n",
    "    #F = G.H, F: imagen original, G: imagen degragaga, H:sistema\n",
    "    channels = []\n",
    "    degradated_img = degradated_img / np.max(degradated_img)\n",
    "    for img_channel in cv.split(degradated_img):\n",
    "        #print(img_channel.shape)\n",
    "        psf_padded = center_image(img_channel, psf) ## en esta funcion se utilizará el tamaño de la imagen para \n",
    "                                                    ##crear un nuevo kernel con dicho tamaño.\n",
    "        H = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(psf_padded)))\n",
    "        G = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(img_channel)))\n",
    "        if (wiener_inverse) and (not(sn.any() == None)):           #WIENER OPTION\n",
    "            \n",
    "            psd_img_channel = np.ones((img_channel.shape[0], img_channel.shape[1]))\n",
    "            aux = np.fft.fft2(np.corrcoef(img_channel))\n",
    "            psd_img_channel[0:aux.shape[0], 0:aux.shape[1]] = aux\n",
    "            \n",
    "            sn_matrix = np.zeros((img_channel.shape[0], img_channel.shape[1]))\n",
    "            \n",
    "            np.fill_diagonal(sn_matrix, sn[0])\n",
    "            \n",
    "            Sn_matrix = np.fft.fft2(sn)\n",
    "            \n",
    "            noise_relation = np.abs( Sn_matrix/ psd_img_channel) + 256*256\n",
    "            #print(noise_relation)\n",
    "            H = H + 10\n",
    "            W = H.conj()/((H*H.conj()) + noise_relation)\n",
    "            #W = np.where(W == 0, W, 1)\n",
    "            F = np.multiply(G, W)\n",
    "            f = np.abs(np.fft.ifftshift((np.fft.ifft2(np.fft.ifftshift(F)))))\n",
    "            #print(f.max())\n",
    "            #print(f.min())\n",
    "            maximum = np.max(f)\n",
    "            f = np.uint8((f/maximum)*256)\n",
    "        else:                        #INVERSE_SIMPLE OPTION\n",
    "            #H = np.where(H == 0, H, 1)\n",
    "            F = np.divide(G, H + 10)\n",
    "            f = np.abs(np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(F))))\n",
    "            maximum = np.max(f)\n",
    "            f = np.uint8((f/maximum)*256)\n",
    "        #print(f.max())\n",
    "        #print(f.min())\n",
    "        \n",
    "        #cv2_imshow('channel', f)\n",
    "        #cv.waitKey(0)\n",
    "        #cv.destroyAllWindows()\n",
    "        channels.append(f)\n",
    "        \n",
    "    if len(channels) > 1:\n",
    "        clean_img = cv.merge(channels)\n",
    "        \n",
    "    \n",
    "    return clean_img\n",
    "\n",
    "def mse_metric(x, y):\n",
    "    a = x.shape[0]\n",
    "    b = x.shape[1]\n",
    "    c = x.shape[2]\n",
    "    x = x.reshape(1, a*b*c)\n",
    "    y = y.reshape(1, a*b*c)\n",
    "    return  np.mean((x - y)**2)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 86.77205912272136\n",
      "MSE inverse_simple 89.96910603841145\n",
      "MSE Wiener 86.15191141764323\n"
     ]
    }
   ],
   "source": [
    "noise_shape = (lenna_blur_noise.shape[0], lenna_blur_noise.shape[1])\n",
    "noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "wiener_result = recover_v2(lenna_blur_noise, kernel, sn=noise, wiener_inverse=True)\n",
    "inverse_simple = recover_v2(lenna_blur_noise, kernel, wiener_inverse=False)\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, lenna_blur_noise)}')\n",
    "print(f'MSE inverse_simple {mse_metric(original, inverse_simple)}')\n",
    "print(f'MSE Wiener {mse_metric(original, wiener_result)}')\n",
    "\n",
    "wiener_vs_inverse_stacked = np.hstack((lenna_blur_noise, inverse_simple, wiener_result))\n",
    "cv2_imshow('degradated <LEFT>, inverse_simple <CENTER> and Wiener <RIGHT>', wiener_vs_inverse_stacked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "qFsvKj7TT-IT"
   },
   "outputs": [],
   "source": [
    "def estimate_blur_kernel(img):\n",
    "  #estimated = None\n",
    "  estimated = (1/9)*np.ones((4, 4))\n",
    "  return estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "SGuaPO9tQgxt",
    "outputId": "ba8dfb35-63b0-4a96-c798-152d11d0c4f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiener vs Inverse\n",
      "Wiener vs Inverse\n"
     ]
    }
   ],
   "source": [
    "for name in test_filenames:\n",
    "  img = cv.imread(name)\n",
    "  if img.any() == None:\n",
    "        print(\"invalid image\")\n",
    "  noise_shape = (img.shape[0], img.shape[1])\n",
    "  # assuming noise_sigma based on lena... should change the estimated value\n",
    "  # based on the new image \n",
    "  noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "  kernel = estimate_blur_kernel(img)\n",
    "  wiener_result = recover_v2(img, kernel, sn=noise, wiener_inverse=True, show = False)\n",
    "  inverse_result = recover_v2(img, kernel, wiener_inverse=False, show = False)\n",
    "  stacked = np.hstack((wiener_result, inverse_result))\n",
    "  cv2_imshow('wiener vs inverse', stacked)\n",
    "  cv.waitKey(0)\n",
    "  cv.destroyAllWindows()\n",
    "  print('Wiener vs Inverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blind Deconvolution\n",
    "\n",
    "Blind Deconvolution (Deconvolución a ciegas) consiste en un algoritmo que reconstruye la imagen sin necesidad de tener el modelo exacto de la función \"PSF\" (es por esto que se le da el nombre de \"a ciegas\"). El algortimo parte de una función PSF \"a priori\", o supone una forma de función PSF, pero luego la ajusta según la imagen de entrada. Para ajustar la función PSF, el algoritmo suele usar las secciones más brillantes de la imagen, que se vieron menos afectadas por el nivel de ruido.\n",
    "Para la implementación, se utilizó la función \"deconvblind\" de Matlab, a la que se la paso la sencilla función PSF a priori como una matriz de 12x12 de unos. Con esto logro obtenerse resultados aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_code_img = cv.imread('deconvCodeMATLAB.png')\n",
    "#print(matlab_code_img)\n",
    "cv.imshow('matlab code deconvblind', matlab_code_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image_blind = cv.imread('image_in_deconvblind.bmp') \n",
    "out_image_blind = cv.imread('image_out_deconvblind.bmp') \n",
    "in_out_images = np.hstack((in_image_blind, out_image_blind))\n",
    "cv.imshow('in image -LEFT- vs out -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Blur\n",
    "\n",
    "Para simular el motion blur que degrada una imagen debido a un movimiento de una cámara al momento de tomar la foto, se realizan kernels con unos en una columna (en caso de motion vertical) o en una fila (en caso de blur horizonral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_h_motion = np.zeros((20, 20))\n",
    "kernel_v_motion = np.zeros((20, 20))\n",
    "\n",
    "k = 1 / 20\n",
    "\n",
    "kernel_h_motion[2, :] = k\n",
    "\n",
    "kernel_v_motion[:, 2] = k\n",
    "\n",
    "\n",
    "\n",
    "#print(kernel_v_motion)\n",
    "#print(kernel_h_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertical Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 86.298583984375\n",
      "MSE recovered 92.0057373046875\n"
     ]
    }
   ],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "vertical_moved = cv.filter2D(original, -1, kernel_v_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#vertical_recovered = recover(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "vertical_recovered = recover_v2(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=False, show = False)\n",
    "in_out_images = np.hstack((original, vertical_moved, vertical_recovered))\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, vertical_moved)}')\n",
    "print(f'MSE recovered {mse_metric(original, vertical_recovered)}')\n",
    "\n",
    "\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizontal Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE degradated 82.41682434082031\n",
      "MSE recovered 106.2109375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "horizontal_moved = cv.filter2D(original, -1, kernel_h_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#horizontal_recovered = recover(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "horizontal_recovered = recover_v2(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "in_out_images = np.hstack((original, horizontal_moved, horizontal_recovered))\n",
    "\n",
    "print(f'MSE degradated {mse_metric(original, horizontal_moved)}')\n",
    "print(f'MSE recovered {mse_metric(original, horizontal_recovered)}')\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_reconstruction - Copy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (images)",
   "language": "python",
   "name": "images"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
