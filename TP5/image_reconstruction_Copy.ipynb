{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BAdRit5-S_gJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OXFKDubES_hj"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from numpy import std, pad, amax, abs\n",
    "from numpy.random import normal\n",
    "from numpy.fft import fftshift, ifftshift, fft2, ifft2 \n",
    "from cv2 import imshow as cv2_imshow\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5Ks3bQw6S_iA"
   },
   "outputs": [],
   "source": [
    "# Filenames\n",
    "filename = './pics/lenna.jpg'\n",
    "test_filenames = ['./pics/barraxx.bmp', './pics/BDBOB.jpg',\n",
    "                  './pics/pru2old.bmp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V00izQfS_lx"
   },
   "source": [
    "# Show original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "-bXscyVmS_l6",
    "outputId": "e8ed658a-9fdb-4326-a3fe-df5442a1bccb"
   },
   "outputs": [],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "cv.imshow(winname = 'original', mat = original)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnekptJeS_ma"
   },
   "source": [
    "# Blur + Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "apfi9kHyS_md"
   },
   "outputs": [],
   "source": [
    "def noisy_gauss(image, snr=20):\n",
    "      row, col, ch = image.shape\n",
    "      sigma_image = std(image)\n",
    "      sigma_noise = np.sqrt(sigma_image**2 * 10**(-snr/10))\n",
    "      noise = normal(loc=0.0, scale=sigma_noise, size=image.shape)\n",
    "      noisy = image + noise\n",
    "      noisy = np.where(noisy < 0,  0, noisy)\n",
    "      noisy = np.where(noisy > 255, 255, noisy)\n",
    "      noisy = noisy.astype(dtype=np.uint8)\n",
    "      return noisy, sigma_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wiQzE9XlS_nw"
   },
   "outputs": [],
   "source": [
    "kernel_shape = (5, 5)\n",
    "lenna_blur = cv.blur(src=original, ksize=(5, 5))\n",
    "lenna_blur_noise, noise_sigma = noisy_gauss(image=lenna_blur, snr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "9UJUdwJgXnWF",
    "outputId": "5a4071fe-ab7c-4e40-d28c-121cfe02e441"
   },
   "outputs": [],
   "source": [
    "cv2_imshow('lena blured and noisy',lenna_blur_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82pZBg_xbq36"
   },
   "source": [
    "# Wiener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "VSVizJYwbk9o"
   },
   "outputs": [],
   "source": [
    "kernel = 1 / kernel_shape[0] / kernel_shape[1]\n",
    "kernel *= np.ones(shape=kernel_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[145, 138, 151, ..., 108, 113, 117],\n",
       "        [150, 117, 150, ..., 121, 120, 113],\n",
       "        [127, 143, 132, ...,  84,  82,  88],\n",
       "        ...,\n",
       "        [ 30,  35,  12, ...,  55,  27,  68],\n",
       "        [  3,   0,   8, ...,  71,  89,  63],\n",
       "        [ 28,  36,  26, ...,  82,  52,  29]], dtype=uint8),\n",
       " array([[115, 138, 128, ..., 122, 107, 117],\n",
       "        [ 95, 129, 154, ..., 127,  97, 112],\n",
       "        [142, 137, 124, ...,  72, 102,  53],\n",
       "        ...,\n",
       "        [ 10,  40,  42, ...,  37,  39,  48],\n",
       "        [ 35,  12,   8, ...,  58,  57,  59],\n",
       "        [ 21,  42,  41, ...,  56,  45,  53]], dtype=uint8),\n",
       " array([[163, 167, 109, ..., 125, 128, 141],\n",
       "        [137, 122, 133, ..., 125, 138,  96],\n",
       "        [132, 134, 126, ...,  80, 100,  78],\n",
       "        ...,\n",
       "        [ 54,  29,  31, ...,  14,  28,  54],\n",
       "        [ 40,  55,  45, ...,  61,  45,  41],\n",
       "        [ 34,  43,  35, ...,  33,  77,  55]], dtype=uint8)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.split(lenna_blur_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "yGTHZmGusV5n"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-b08309efc1ad>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-b08309efc1ad>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    wiener_filter = np.divide(np.multiply(H.conjugate(), sf), np.multiply((np.abs(H))**2, sf) + sn ) )\u001b[0m\n\u001b[1;37m                                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def recover(img, h, sn=None, wiener_inverse=False, show = True):\n",
    "    \n",
    "  #preparing H  \n",
    "  a, b, _ = img.shape\n",
    "  padded_kernel = np.zeros(shape=(a, b))\n",
    "  c, d = h.shape\n",
    "  padded_kernel[a//2 - c//2:a//2 + c//2 +1, b//2 - d//2: b//2 + d//2 +1] = h\n",
    "  centered_fft2_kernel = fftshift(fft2(padded_kernel))\n",
    "  #centered_fft2_kernel += 1.2\n",
    "  H = centered_fft2_kernel\n",
    "\n",
    "  channels = []\n",
    "  for channel in cv.split(img):  #channel represents each R, B and G channel.\n",
    "    channel_fft = fftshift(fft2(channel))\n",
    "    if wiener_inverse:\n",
    "      sf = channel_fft\n",
    "      wiener_filter = np.divide(np.multiply(H.conjugate(), sf), np.multiply((np.abs(H))**2, sf) + sn ) )\n",
    "      clean_lena = np.multiply(chanel_fft, wiener_filter)\n",
    "      #clean_lena = np.multiply(np.divide(channel_fft, H), np.divide(np.abs(H)**2, (np.abs(H)**2 + np.divide(sn,sf))))\n",
    "    else:\n",
    "      clean_lena = np.divide(channel_fft, H)\n",
    "\n",
    "    # filtered image ifft2 and normalize to unity\n",
    "    clean_lena = np.abs(ifft2(ifftshift(clean_lena)))\n",
    "    maximum = amax(clean_lena)\n",
    "    clean_lena /= maximum\n",
    "    clean_lena *= 255\n",
    "    clean_lena = clean_lena.astype(np.uint8)\n",
    "    channels.append(clean_lena)\n",
    "\n",
    "  if len(channels) > 1:\n",
    "    clean_lena = cv.merge(channels)\n",
    "  else:\n",
    "    clean_lena = channels\n",
    "  newww = np.hstack((clean_lena, img))\n",
    "  if show:\n",
    "        cv2_imshow('recovered <LEFT>, original <RIGHT>', newww)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "  return clean_lena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "VuJjD7nBHRRy",
    "outputId": "95cc9461-ff99-4419-ec9e-56847c478e44"
   },
   "outputs": [],
   "source": [
    "noise_shape = (lenna_blur_noise.shape[0], lenna_blur_noise.shape[1])\n",
    "noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "wiener_result = recover(img=lenna_blur_noise, h=kernel, sn=noise, wiener_inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BPiaiLMLKxq"
   },
   "source": [
    "# Inverse Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "Qk6SbUFVLHzn",
    "outputId": "9b23649d-67e1-4562-c701-fa4c158a410b"
   },
   "outputs": [],
   "source": [
    "inverse_result = recover(img=lenna_blur_noise, h=kernel, wiener_inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "70Veee5aNPU9",
    "outputId": "00e24e81-c87c-4181-e197-077af2105c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiener vs Inverse\n"
     ]
    }
   ],
   "source": [
    "stacked = np.hstack((wiener_result, inverse_result))\n",
    "cv2_imshow('wiener vs inverse_simple', stacked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "print('Wiener vs Inverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qFsvKj7TT-IT"
   },
   "outputs": [],
   "source": [
    "def estimate_blur_kernel(img):\n",
    "  #estimated = None\n",
    "  estimated = (1/9)*np.ones((3, 3))\n",
    "  return estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "SGuaPO9tQgxt",
    "outputId": "ba8dfb35-63b0-4a96-c798-152d11d0c4f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiener vs Inverse\n",
      "Wiener vs Inverse\n",
      "Wiener vs Inverse\n"
     ]
    }
   ],
   "source": [
    "for name in test_filenames:\n",
    "  img = cv.imread(name)\n",
    "  if img.any() == None:\n",
    "        print(\"invalid image\")\n",
    "  noise_shape = (img.shape[0], img.shape[1])\n",
    "  # assuming noise_sigma based on lena... should change the estimated value\n",
    "  # based on the new image \n",
    "  noise = np.ones(shape=noise_shape) * noise_sigma**2\n",
    "\n",
    "  kernel = estimate_blur_kernel(img)\n",
    "  wiener_result = recover(img=img, h=kernel, sn=noise, wiener_inverse=True)\n",
    "  inverse_result = recover(img=img, h=kernel, wiener_inverse=False)\n",
    "  stacked = np.hstack((wiener_result, inverse_result))\n",
    "  cv2_imshow('wiener vs inverse', stacked)\n",
    "  cv.waitKey(0)\n",
    "  cv.destroyAllWindows()\n",
    "  print('Wiener vs Inverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blind Deconvolution\n",
    "\n",
    "Blind Deconvolution (Deconvolución a ciegas) consiste en un algoritmo que reconstruye la imagen sin necesidad de tener el modelo exacto de la función \"PSF\" (es por esto que se le da el nombre de \"a ciegas\"). El algortimo parte de una función PSF \"a priori\", o supone una forma de función PSF, pero luego la ajusta según la imagen de entrada. Para ajustar la función PSF, el algoritmo suele usar las secciones más brillantes de la imagen, que se vieron menos afectadas por el nivel de ruido.\n",
    "Para la implementación, se utilizó la función \"deconvblind\" de Matlab, a la que se la paso la sencilla función PSF a priori como una matriz de 12x12 de unos. Con esto logro obtenerse resultados aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_code_img = cv.imread('deconvCodeMATLAB.png')\n",
    "#print(matlab_code_img)\n",
    "cv.imshow('matlab code deconvblind', matlab_code_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image_blind = cv.imread('image_in_deconvblind.bmp') \n",
    "out_image_blind = cv.imread('image_out_deconvblind.bmp') \n",
    "in_out_images = np.hstack((in_image_blind, out_image_blind))\n",
    "cv.imshow('in image -LEFT- vs out -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Blur\n",
    "\n",
    "Para simular el motion blur que degrada una imagen debido a un movimiento de una cámara al momento de tomar la foto, se realizan kernels con unos en una columna (en caso de motion vertical) o en una fila (en caso de blur horizonral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_h_motion = np.zeros((21, 21))\n",
    "kernel_v_motion = np.zeros((21, 21))\n",
    "\n",
    "k = 1 / 21\n",
    "\n",
    "kernel_h_motion[2, :] = k\n",
    "\n",
    "kernel_v_motion[:, 2] = k\n",
    "\n",
    "\n",
    "\n",
    "#print(kernel_v_motion)\n",
    "#print(kernel_h_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertical Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = cv.imread(filename=filename, flags=cv.IMREAD_COLOR)\n",
    "vertical_moved = cv.filter2D(original, -1, kernel_v_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#vertical_recovered = recover(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "vertical_recovered = recover(vertical_moved, kernel_v_motion, sn= noise, wiener_inverse=False, show = False)\n",
    "in_out_images = np.hstack((original, vertical_moved, vertical_recovered))\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizontal Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "horizontal_moved = cv.filter2D(original, -1, kernel_h_motion)\n",
    "noise = np.ones(shape=(256, 256)) * (noise_sigma/10)**2\n",
    "#horizontal_recovered = recover(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=True, show = False)\n",
    "horizontal_recovered = recover(horizontal_moved, kernel_h_motion, sn= noise, wiener_inverse=False, show = False)\n",
    "in_out_images = np.hstack((original, horizontal_moved, horizontal_recovered))\n",
    "cv.imshow('original - LEFT- moved image -CENTER- vs recovered -RIGHT-', in_out_images)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_reconstruction - Copy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (images)",
   "language": "python",
   "name": "images"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
